
% !TEX root = /Users/zhuzhuangdi/Desktop/MSUCourses/MachineLearning847/17spr_wang_zhu_du/Final/final_report.tex
\section{Conclusion and Future Work} 

In this project, we propose and implement three different approaches to generate Chinese Song Ci automatically: a traditional Genetic Algorithm Model, a Recurrent Neural Network model, and a Generative Adversarial Network model, respectively.
%
For traditional approach, its advantage is that the output will always follow the structure or rhyme rules of Song Ci by evaluating each candidate agains an evaluation function,  and only the candidate with a satisfying evaluation value will be chosen as the output.
%
For the two deep learning approaches using neural networks, its advantage is that no pre-definend constraints are need for the model, as  the sophisticated rules for each genre of Song Ci can be learned automatically by a large set of training data.

The human evaluation shows that all of the three approaches succeed in generating Song Ci with the correct structure and gramma rules. For GA model and RNN model, not only can they generate Song Ci with the same rhymes, they can also generate Song Ci with consistent semantic meanings which receives high scores by human evaluation. 

To further improve the qualities of generation, we can adopt the knowledge based method that can incorporate extra sources of knowledges. Previews work \cite{wang2016baidu} showed that by using extract knowledges from encyclopedia, the RNNs model can write the poem in topic which cannot find in the ancient Chinese poems. 

Also, a systematic evaluation is necessary to rate each model. Popular automatic evaluation method, like BLEU, cannot provide a comprehensive metric as human evaluation\cite{iu2016evaluate}. For this reason, we may need to organize human evaluation to evaluate all the results generated by our models.

Finally, RNNs has various structures and we may benefit from advanced RNN models. For example, attention-based RNN and Lookback RNN \cite{lookbackRNN} already prove it can efficiently generate musics. These models should further improve the results.


Our future work would be applying our models to other forms of text generation task, such as generating Yuan Qu, or generating poems in other languages.


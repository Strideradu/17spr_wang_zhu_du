% !TEX root = /Users/zhuzhuangdi/Desktop/MSUCourses/MachineLearning847/17spr_wang_zhu_du/Final/final_report.tex
\section{Problem Description}
\subsection{Motivation}
%
In this project, we propose and evaluate different approaches to automatically generate Chinese poems.
% 
Ci is one of the most important genres of Chinese classical poetry.  
%
As a precious cultural heritage, not many of them have been passed down onto the current generation.
%
Therefore, the study of automatic generation of Ci is meaningful, not only because it supplements entertainment and education resources to modern society, but also because it demonstrates the feasibility of applying artificial intelligence in Art generation.
%

\subsection{Background}
Song Ci is a precious cultural heritage in China, which refers to Classical Chinese poetry typical of the Song dynasty.
%
It arose with the so-called banquet music in Tang dynasty and reached its peak one hundred years later, as a major alternative to Shi poetry\cite{cai2008chinesepoetry} .


Derived from the structure used in Tang poetry, Ci follows more complex and strict rules.
%
There are more than 800 genres for Ci, which is called Cipai\cite{wikici}.
%
Each Cipai determine the number of characters for different lines, the arrangement of rhyme, and even the location of tones.
%
To create a Song Ci in a specified Cipai, authors need to fill in the words according to the rule matrix associated with that Cipai.
 %
 The uneven lines in Ci follow more continuous syntax consistency than traditional Chinese Tang poetry\cite{cai2008chinesepoetry}.

These complex rules for Song Ci make it difficult for AI systems to generate Song Ci with good property on structure or meaning consistency.
%
Besides, compared with Tang poetry, the number of available Song Ci in a specified Cipai is relatively small, which means we have limited numbers of training data to build any model.


\subsection{Proposed Approaches}
%
We propose one traditional approach named Genetic Algorithms, and two deep-learning approaches named Recurrent Neural Networks and Generative Adversarial Networks, respectively.
\begin{itemize}
\item { Genetic Algorithms (GA).} 
%
We implement genetic algorithm based on the method proposed by Zhou et al.\cite{zhou2010genetic}.
%
This approach implement a fitness function that is designed for evaluate the performance of Song Ci by considering the level and oblique tones-based coding method and the syntactic and semantic correctness.
%
Thus additional information is needed, for example tone pattern and rhythm of words, syntactic pattern of sentences with different length and format of different Cipai.
%
We use Cipai title and keywords as input to generate Song Ci that is strictly following the format and tone pattern of that Cipai.
%%%%%% 
\item {Recurrent Neural Network (RNN).} 
%
We train a RNN model by feeding sentences of Song Ci as the input, and ask the RNN model to generate the probability distribution of the next character in the sentence, given the sequence of previous characters.
%
Especially, to capture the long term semantic dependencies between characters in Song Ci,
%
we apply Long Short Term Memory units in the RNN model.
%
\item{Generative Adversarial Networks (GANs).}  We want train a sequential GANs model combined a LSTM-cell RNN model as generator and a CNNs as discriminator for Song Ci data. We hope this model can generate Song Ci close to poem written by human.
%
\end{itemize}
We will compare the results generated by different approaches with respect to the structure, rhythmic and semantic consistency. 
 

\subsection{Technical Challenges and Proposed Solutions} 
The first challenge to build a general model for all types of Song Ci.
%
Different from Shi poetry whose structure is strict,  Song Ci has more than 800 set of Cipai, and different Cipai follows different structural or rhythmic patterns.
%
Therefore, it is difficult to generalize templates or rules for all the Song Ci from limited training dataset.
%
We explore with three approaches to address this challenge.
%: a traditional model using GA, and two deep-learning models using RNN and GAN, respectively. 
%
For the GA approaches, {we organize a set of rules, such as the tone patterns and rhythms of words, the syntactic patterns of sentences with different length, and the structure constraints of different Cipai, so that only candidate poems that satisfy these rules will be chosen as the output.}
% 
For the RNN model and the GAN approaches, we do not set any pre-defined constraints, but feed our model with carefully organized training data, so that the grammatical and rhythmic rules can be automatically captured during the training.
%%%%%%%%%

The second challenge is to extract features that retain both rhythmic and semantic relevance among characters in our training corpus. 
%
Our solution is to use a word-embedding matrix to map each character in the corpus into a vector representation
% 
Therefore, characters with similar meanings or same rhymes will have smaller distance in the vector space.


The third challenge is to maintain consistent and poetic meanings throughout the generated Song Ci.
%
{
For GA approach, we implement a fitness function to evaluate the performance of Song Ci. Each candidate Song Ci generated by this model will be evaluated on the fitness level , oblique tones-based coding method, and the syntactic and semantic correctness.}
%
For the RNN approach, since Song Ci are much longer in length and therefore more complicated in context compared with Shi poetry, it is difficult to keep long-distance memory using conventional RNN.
%
Therefore, we use a Long Short Term Memory (LSTM) model that can track the long-distance semantic information automatically.
% 

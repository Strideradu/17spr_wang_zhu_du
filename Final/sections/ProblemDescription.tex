% !TEX root = /Users/zhuzhuangdi/Desktop/MSUCourses/MachineLearning847/17spr_wang_zhu_du/Final/final_report.tex
\section{Problem Description}
\subsection{Motivation}  
%
In this project, we propose and evaluate different approaches to automatically generate Chinese poems. 
%
Ci is one of the most important genres of Chinese classical poetry. 
%
As a precious cultural heritage, not many of them have been passed down onto the current generation.
%
Therefore, the study of automatic generation of Ci is meaningful, not only because it supplements entertainment and education resources to modern society, but also because it demonstrates the feasibility of applying artificial intelligence in Art generation. 
%

\subsection{Background}
Song Ci is a precious cultural heritage in China, which refers to Classical Chinese poetry typical of the Song dynasty.
%
It arose with the so-called banquet music in Tang dynasty and reached its peak one hundred years later, as a major alternative to Shi poetry\cite{cai2008chinesepoetry} .


Derived from the structure used in Tang poetry, Ci follows more complex and strict rules.
%
There are more than 800 genres for Ci, which is called Cipai\cite{wikici}. 
%
Each Cipai determine the number of characters for different lines, the arrangement of rhyme, and even the location of tones.
%
To create a Song Ci in a specified Cipai, authors need to fill in the words according to the rule matrix associated with that Cipai.
 %
 The uneven lines in Ci follow more continuous syntax consistency than traditional Chinese Tang poetry\cite{cai2008chinesepoetry}.
 
These complex rules for Song Ci make it difficult for AI systems to generate Song Ci with good peropery on structure or meaning consistency.
%
Besides, compared with Tang poetry, the number of available Song Ci in a specified Cipai is relatively small\cite{}, which means we have limited numbers of training data to build any model. 


\subsection{Proposed Approaches} 
%
We propose one traditional approach, and two deep-learning approaches to generate Song Ci, respectively.
%
For traditional approach, we use Genetic Algorithms (GAs).
%
 \wei{More contents here.}
%%%%%%
For deep learning approaches, our first model is to use a Recurrent Neural Network (RNN).
%
We train a RNN model by feeding sentences of SongCi as the input, and ask the RNN model to generate the probability distribution of the next character in the sentence, given the sequence of previous characters.
%
Especially, to capture the long term semantic dependencies between characters in Song Ci,
%
we apply Long Short Term Memory units in the RNN model. 
%%%%%
Another deep learning approach is to use Generative Adversarial Networks (GANs).
%
\nan{More content here}.
%
We will compare the results generated by different approaches with respect to the structure, rhythmic and semantic consistency.
 
\subsection{Technical Challenges and Solutions} 
The first challenge to build a general model for all types of Song Ci.
%
Different from Shi poetry whose structure is strict,  Song Ci has more than 800 set of Cipai, and different Cipai follows different structural or rhythmic patterns.
%
Therefore, it is difficult to generalize templates or rules for all the Song Ci from limited training dataset.
% 
We explore with three approaches to address this challenge: a traditional model using GA, and two deep-learning models using RNN and GAN, respectively.
%
In the traditional GA model, \wei{More content here}.
% 
In the RNN model and the GAN model, we do not set any pre-defined constraints, but feed our model with carefully organized training data, so that the grammatical and rhythmic rules can be automatically captured during the training.
%%%%%%%%%

The second challenge is to extract features that retain both rhythmic and semantic relevance among characters in our training corpus. 
%
Our solution is to use a word-embedding matrix to map each character in the corpus into a vector representation
%
Therefore, the distance between characters with relevant meanings will be more close . 
%%%%%%%%%

The third challenge is to maintain consistent and poetic meanings throughout the generated SongCi.
%
Compared with Shi poetry, Song Ci are much longer in length and therefore more complicated in context.
%
It is difficult to keep long-distance memory using conventional RNN.
% 
Our solution is to use a Long Short Term Memory (LSTM) model that can track the long-distance semantic information automatically. 